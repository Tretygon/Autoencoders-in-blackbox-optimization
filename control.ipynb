{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import main\n",
    "import storage\n",
    "import ranks\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from itertools import takewhile,dropwhile\n",
    "from fractions import Fraction\n",
    "import pd_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = storage.merge_and_load()\n",
    "# df=df[~(df['note'] == 'ForcedSpecimen0')]\n",
    "# storage.overwrite(df)\n",
    "# 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import storage, ranks\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from itertools import takewhile,dropwhile\n",
    "from fractions import Fraction\n",
    "import pd_cols\n",
    "import math\n",
    "import scipy.stats\n",
    "import scipy\n",
    "def p(func, /, *args, **keywords):\n",
    "    def newfunc(*fargs, **fkeywords):\n",
    "        newkeywords = {**keywords, **fkeywords}\n",
    "        return func(*args, *fargs, **newkeywords)\n",
    "    newfunc.func = func\n",
    "    newfunc.args = args\n",
    "    newfunc.keywords = keywords\n",
    "    return newfunc\n",
    "\n",
    "if False: #delete the all experiment records\n",
    "        shutil.rmtree(\"ppdata\")\n",
    "        shutil.rmtree(\"exdata\")\n",
    "        shutil.rmtree(\"graphs\")\n",
    "\n",
    "df_og = storage.merge_and_load()\n",
    "df_og = df_og[(df_og['note']=='') | (df_og['note']=='none') ]\n",
    "df_og['full_desc'] = df_og.apply(pd_cols.get_full_desc,axis=1)\n",
    "df_og = ranks.compute_ranks(df_og)\n",
    "\n",
    "# helper functions and axilliary data \n",
    "pd.options.mode.chained_assignment = None          # prevents displaying a useless warning\n",
    "\n",
    "def df_enhance(df):\n",
    "        # df['true_evaluations'] = (df['pop_size'] * df['true_ratio']).map(int)\n",
    "        df['gen_mult'] = df['gen_mult'].map(int) \n",
    "        df['dim_red'] = df['dim_red'].replace('','none')\n",
    "        df['model'] = df['model'].replace('','none')\n",
    "        df['pop_size'] = df['pop_size'].replace('None','none')\n",
    "        df['actual_pop_size'] = df.apply(lambda r: r['pop_size'] if r['pop_size'] != 'none' else 4 + math.floor(3 * math.log(r['dim'])),axis=1)\n",
    "        df['dim_red_kind'] = df['dim_red'].map(lambda a: (''.join(takewhile(lambda s: s.isalpha(), a))).lower())\n",
    "        df['model_kind'] = df['model'].map(lambda a: (''.join(takewhile(lambda s: s.isalpha(), a))).lower())\n",
    "        df['surrogate'] = df['model'].map(lambda a: (''.join(takewhile(lambda s: s.isalnum(), a))).lower())\n",
    "        # df['spearman_corr'] = df['spearman_corr'].map(np.nan_to_num)\n",
    "        # df['spearman_pval'] = df['spearman_pval'].map(np.nan_to_num)\n",
    "        return df\n",
    "\n",
    "df_og = df_enhance(df_og)\n",
    "# df_og = df_og[df_og['scale_train']]\n",
    "pure_mask = df_og['gen_mult'].map(int) == 1\n",
    "pures = df_og[pure_mask] \n",
    "# pures2 = df_og[df_og['scale_train']==Tru] \n",
    "\n",
    "# pca_mask = (df_og['model_kind'] == 'gp')&(df_og['dim_red_kind'] == 'pca')&((df_og['pop_size']==48)|(df_og['pop_size']==64))&(df_og['true_ratio'].map(Fraction)==Fraction(1/8))\n",
    "# pca_df = df_og[pca_mask] \n",
    "\n",
    "# keep the special cases separate, it makes all the graphing easier\n",
    "df_og = df_og[~(\n",
    "       (pure_mask&(df_og['pop_size'] != 'none'))\n",
    "    #    |(pca_mask&(df_og['dim_red'] != 'pca0.5'))   \n",
    ")]  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = storage.merge_and_load()\n",
    "# df['model_kind'] = df['model'].map(lambda a: (''.join(takewhile(lambda s: s.isalpha(), a))).lower())\n",
    "# # df[df['model_kind']=='doe']['dists'] = [d[-len(c):] for d,c in  zip(df[df['model_kind']=='doe']['dists'].to_list(),df[df['model_kind']=='doe']['correct_invariant'].to_list())]\n",
    "# df['dists'] = df.apply(lambda r: r['dists'][-len(r['correct_invariant']):] if r['model_kind']=='doe' else r['dists'],axis=1)\n",
    "# print()\n",
    "# storage.overwrite(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " <>:5: SyntaxWarning:\"is\" with a literal. Did you mean \"==\"?\n",
      " <>:5: SyntaxWarning:\"is\" with a literal. Did you mean \"==\"?\n",
      " C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4344\\1961603376.py:5: SyntaxWarning:\"is\" with a literal. Did you mean \"==\"?\n"
     ]
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "def xy_scatter(xs, ys, len_mod_s, len_mod_e, xdesc, ydesc):\n",
    "    fig, ax = plt.subplots()\n",
    "    if xs is 'index':\n",
    "        xs, ys = list(zip(*[(i,item) for arr in  xs.to_list() for (i,item) in enumerate(arr[int(len(arr)*len_mod_s):int(len(arr)*len_mod_e)])]))\n",
    "    else:\n",
    "        xs = np.array([item for arr in  xs.to_list() for item in arr[int(len(arr)*len_mod_s):int(len(arr)*len_mod_e)]])\n",
    "        ys = np.array([item for arr in  ys.to_list() for item in arr[int(len(arr)*len_mod_s):int(len(arr)*len_mod_e)]])\n",
    "   \n",
    "    \n",
    "    not_nan = ~(np.isnan(xs)|np.isnan(ys))\n",
    "    xs, ys=np.array(xs)[not_nan], np.array(ys)[not_nan]\n",
    "    ax.scatter(xs, ys, marker='.')\n",
    "    \n",
    "    # m, b = np.polyfit(dists, corr_invariant_tracker, 1)\n",
    "    lr = scipy.stats.linregress(xs, ys)\n",
    "    xx = np.linspace(np.min(xs), np.max(xs), num=100)\n",
    "    ax.plot(xx, lr.slope*xx + lr.intercept,color='red')\n",
    "    txt = [\n",
    "        \"r^2 = {:.3f}\".format(lr.rvalue**2),\n",
    "        'linreg start: {:.3f}'.format(lr.intercept),\n",
    "        'linreg end: {:.3f}'.format(lr.slope*np.max(xs) + lr.intercept),\n",
    "\n",
    "    ]\n",
    "    ax.annotate('\\n'.join(txt), (0.8*np.max(xs), 0.8*np.max(ys)))\n",
    "    ax.set_xlabel(xdesc.title())\n",
    "    ax.set_ylabel(ydesc.title())\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_layer_tics(ax):\n",
    "        plt.xticks(rotation=0, size= 'xx-small')\n",
    "        for tick in ax.xaxis.get_major_ticks()[1::2]:\n",
    "                tick.set_pad(15)\n",
    "def save_and_show(name:str, show=True):\n",
    "        plt.savefig(f'graphs/{name}.png', bbox_inches='tight')\n",
    "        if show: plt.show()\n",
    "def print_latex(df: pd.Series):\n",
    "        r = lambda s: ' ' if r is None else s.replace('_', ' ')\n",
    "        s= \"\\\\begin{tabular}{|lc|}\\n\"  # + \" | \".join([\"c\"] * len(df.columns)) + \"}\\n\"\n",
    "        s+= \"\\\\hline\\n\"\n",
    "        s+= r(df.index.name) + ' & ' + r(df.name) +'\\\\\\\\\\n'\n",
    "        s+= \"\\\\hline\\n\"\n",
    "        for k, v in df.items():\n",
    "                s+= f\"{k} & {v:0.2f} \\\\\\\\\\n\"\n",
    "        s+= \"\\\\hline\\n\"\n",
    "        s+= \"\\\\end{tabular}\"\n",
    "        print(s)\n",
    "def np_apply_axis0(fn=None):\n",
    "        def inner(arr, fn):\n",
    "                arr = arr.to_list()\n",
    "                b = np.apply_along_axis(fn,0,arr) \n",
    "                return list(b)\n",
    "        return lambda a: inner(a, fn)\n",
    "def avg_axis0_rugged(arr):\n",
    "        arr = arr.to_list()\n",
    "        m_l = max(map(len, arr))\n",
    "        masks = []\n",
    "        padded = []\n",
    "        for a in arr:\n",
    "                to_pad = m_l-len(a)\n",
    "                mask = [True]*len(a) + [False]*(to_pad)\n",
    "                p_arr = np.pad(a,(0, to_pad), constant_values=0)   \n",
    "                padded.append(p_arr)\n",
    "                masks.append(mask)\n",
    "        stacked= np.stack(padded, axis=0)\n",
    "        num_valid_in_each_col = np.sum(np.array(masks),axis=0)\n",
    "        avg = np.sum(stacked, 0)/num_valid_in_each_col\n",
    "        return list(avg)\n",
    "\n",
    "def close_to(series, num):\n",
    "        return series.map(lambda a: abs(a - num) <= 1e-3)\n",
    "\n",
    "def get_param_desc_title(df):\n",
    "    title_stringer = lambda beginning, name: beginning + ' ' + str(df[name].min()) + (('-'+str(df[name].max())) if df[name].min() != df[name].max() else '')\n",
    "    title = title_stringer('fun','function') + '; dim ' + ', '.join([str(a) for a in np.unique(df['dim'])]) + title_stringer('; inst','instance')\n",
    "    return title\n",
    "\n",
    "def default_groupby(df, columns):\n",
    "        map_dict = {\n",
    "                'ranks':np_apply_axis0(np.average), \n",
    "                'avg_rank':'mean', \n",
    "                'last_rank':'mean',\n",
    "                'elapsed_time':'mean',\n",
    "                'model':'first',\n",
    "                'dim_red':'first',\n",
    "                'model_kind':'first',\n",
    "                'dim_red_kind':'first',\n",
    "                'gen_mult':'first'\n",
    "        }\n",
    "        for c in columns:  \n",
    "               if c in map_dict: \n",
    "                      del map_dict[c]\n",
    "        res = df.groupby(columns).agg(map_dict)\n",
    "        return res\n",
    "\n",
    "baselines = default_groupby(pures, ['pop_size'])\n",
    "baseline_color = '#E04836'\n",
    "default_color = 'forestgreen'\n",
    "def bar(df,x_name=None, y_name='avg_rank',  index_mapper = None, y_mapper = None, regr = False, baseline_i=-1, x_ticklabel_mapper=None, print_table=True, title = ''):\n",
    "        if x_name != None:    \n",
    "            df = default_groupby(df,x_name)\n",
    "        df = df.sort_index()\n",
    "        \n",
    "        if print_table is not None:\n",
    "                print(print_table)\n",
    "                print_latex(df[y_name])\n",
    "        colors = [default_color for _ in range(len(df))]\n",
    "        if baseline_i != -1 :\n",
    "                colors += [baseline_color]\n",
    "                df.loc[str(len(df))] = baselines.loc[baseline_i]\n",
    "                \n",
    "        x = df.index\n",
    "        y = df[y_name] \n",
    "        \n",
    "        # if index_mapper != None: \n",
    "        #        x = x.map(index_mapper)\n",
    "        # if y_mapper != None: \n",
    "        #        y = y.map(y_mapper)\n",
    "        ax = sns.barplot(x=x.map(str), y=y, palette=colors)\n",
    "        # fig, ax = plt.subplots()\n",
    "        # ax.bar(x.map(str), y, label=bar_labels, color=bar_colors)\n",
    "        ax.set_ylabel('Rank Percentile')\n",
    "        xn = df.index.name if x_name == None else x_name\n",
    "        if xn != None: # df.index.name can be None\n",
    "                xn = xn.replace('_', ' ').title()\n",
    "                ax.set_xlabel(xn)\n",
    "        xticklabels = ax.get_xticklabels()\n",
    "        if x_ticklabel_mapper:\n",
    "               xticklabels = x_ticklabel_mapper(xticklabels)\n",
    "        if baseline_i != -1 :\n",
    "                xticklabels[-1] = 'baseline'\n",
    "                plt.axhline(y=y[-1], color=baseline_color, linestyle='dotted')\n",
    "        ax.set_xticklabels(xticklabels, size='small')\n",
    "        # from pydoc import locate\n",
    "# >>> locate('int')\n",
    "        # print('\\n'.join(map(lambda (a,b): f'{a}',zip(y,x))))\n",
    "        if regr:\n",
    "                xx = np.arange(len(y)-(1 if baseline_i != -1  else 0))\n",
    "                m, b = np.polyfit(xx, y[:-1] if baseline_i != -1  else y, 1)\n",
    "                ax.plot(xx, m*xx + b,color='red', alpha=0.5)\n",
    "        ax.title = title + '\\n' + get_param_desc_title(df)\n",
    "        return ax \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_og' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dim \u001b[38;5;129;01min\u001b[39;00m dims:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (s,e,description) \u001b[38;5;129;01min\u001b[39;00m func_groups:\n\u001b[1;32m---> 15\u001b[0m         df \u001b[38;5;241m=\u001b[39m \u001b[43mdf_og\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     16\u001b[0m         df \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpop_size\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m     17\u001b[0m         title \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_og' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "gen_lims = [10, 4, 2]\n",
    "dims = [2,5,10, None]\n",
    "fn = None\n",
    "func_groups = [\n",
    "    (1,5, 'Separable Functions'),\n",
    "    (6,9, 'Functions with low or moderate conditioning'),\n",
    "    (10,14, 'Ill conditioned functions'),\n",
    "    (15,19, 'Adequately structured multimodal functions'),\n",
    "    (20,24, 'Weakly structured multimodal functions'),\n",
    "    (1,24, 'All functions')\n",
    "]\n",
    "for eval_limit in gen_lims:\n",
    "    for dim in dims:\n",
    "        for (s,e,description) in func_groups:\n",
    "            df = df_og.copy()\n",
    "            df = df[(df['pop_size']=='none')]\n",
    "            title = []\n",
    "            \n",
    "            if description != '':\n",
    "                # title.append(f'func {s}-{e}')\n",
    "                title.append(description)\n",
    "                df = df[(df['function']>=s)&(df['function']<=e)]\n",
    "            if dim != None:\n",
    "                title.append(f'dim {dim}')\n",
    "                df = df[(df['dim']==dim)]\n",
    "            else: title.append(f'all dims')\n",
    "            \n",
    "            if eval_limit != 1:\n",
    "                a = eval_limit\n",
    "                title.append(f'first 1/{a} generations')\n",
    "                eval_limit = int(50/eval_limit)\n",
    "            title = ', '.join(title)\n",
    "\n",
    "            # df = df[(df['note']=='')|((df['gen_mult']==1)&(df['pop_size']=='none'))]\n",
    "            import math\n",
    "            # df['best_per_sett']\n",
    "            df['improvement_percent'] = df['vals'].apply(lambda a: 100*(1-(a-a[-1])/(a[3]-a[-1])))\n",
    "            df['convergence_cutoff'] = df['improvement_percent'].apply(lambda a: np.argmin(a>99.99))\n",
    "            # df = df[df['convergence_cutoff']>5]\n",
    "            # df['evals'] = df.apply(lambda r: r['evals'][:r['convergence_cutoff']],axis=1)\n",
    "            # df['vals'] = df.apply(lambda r: r['vals'][:r['convergence_cutoff']],axis=1)\n",
    "            \n",
    "\n",
    "            # df = df[(df['model']=='doe_32_8')&(df['dim']==2)]\n",
    "            # xy_scatter(df['dists'],df['spearman_corr'], 0, 1, 'latent space euklidean distance', 'spearman rank correlation')\n",
    "            # xy_scatter(df,'doe_16_4', 0,1, 'dists', 'spearman_pval', 'latent space euklidean distance', 'spearman rank p-value')\n",
    "\n",
    "            df['vals'] = df.apply(lambda r: r['vals'][:eval_limit],axis=1)\n",
    "            df['evals'] = df.apply(lambda r: r['evals'][:eval_limit],axis=1)\n",
    "            df = ranks.compute_ranks(df, eval_limit=eval_limit)\n",
    "            df['surrogate'] = df['model'].map(lambda a: (''.join(takewhile(lambda s: s.isalnum(), a))).lower())\n",
    "            dfg = default_groupby(df, 'surrogate')\n",
    "            # dfg['avg_rank'] = dfg['ranks'].apply(np.mean)\n",
    "            # dfg['median_rank'] = dfg['ranks'].apply(np.median)\n",
    "            ax = bar(dfg,y_name='avg_rank', print_table=title)\n",
    "            plt.title(title)\n",
    "            save_and_show(title.replace('/', ''))\n",
    "            # plt.show()\n",
    "            # for tick in ax.xaxis.get_major_ticks()[1::2]:\n",
    "            #     tick.set_pad(15)\n",
    "            # plt.xticks(size= 25)\n",
    "            # aaaa = avg_axis0_rugged(df['ranks'])\n",
    "            # \n",
    "\n",
    "            # for s,e,description in func_groups:\n",
    "            #     df1 = df[(df['function']>=s)&(df['function']<=e)]\n",
    "            #     ax = bar(dfg,y_name='last_rank')\n",
    "            #     for tick in ax.xaxis.get_major_ticks()[1::2]:\n",
    "            #         tick.set_pad(15)\n",
    "            #     plt.xticks(size= 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_og.copy()\n",
    "df = df[((df['note']=='pop scale, dim scale')|((df['gen_mult']==1))&(df['pop_size']=='none'))&(df['dim']==10)]\n",
    "ranks.coco_plot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'approx_dist'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'approx_dist'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m df_og\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m df[(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mapprox_dist\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m&\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdim\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m \u001b[38;5;241m20\u001b[39m)]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapprox_dist\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe())\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'approx_dist'"
     ]
    }
   ],
   "source": [
    "df = df_og\n",
    "df = df[(df['approx_dist']!= -1)&(df['dim']== 20)]\n",
    "print(df['approx_dist'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_og\n",
    "df = df[(df['approx_dist']!= -1)&(df['dim']!= 40)]\n",
    "print(df['approx_dist'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_og\n",
    "ax = bar(df,'full_desc',)\n",
    "for tick in ax.xaxis.get_major_ticks()[1::2]:\n",
    "    tick.set_pad(15)\n",
    "plt.xticks(size= 5)\n",
    "save_and_show('rrrrr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_og\n",
    "df = default_groupby(df, ['true_ratio'])\n",
    "ax = bar(df,'true_ratio')\n",
    "\n",
    "save_and_show('rrrrr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pures\n",
    "# df = df[df['pop_size']]\n",
    "ax = bar(df, 'pop_size')\n",
    "ax.set_xlabel('Population Size')\n",
    "ax.set_title('Normal Evaluation')\n",
    "\n",
    "save_and_show('pure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca \n",
    "from itertools import takewhile,dropwhile\n",
    "\n",
    "st =False\n",
    "df=pca_df[pca_df['scale_train']==st]\n",
    "df = df[(df['model_kind'] == 'gp')&(df['pop_size']==64)]\n",
    "\n",
    "df['pca_ratio'] = df['dim_red'].map(lambda a: ''.join(dropwhile(lambda s: s.isalpha(), a)))\n",
    "\n",
    "# df1 = df_og[(df_og['model_kind'] == 'gp')&(df_og['dim_red_kind'] == 'none')&(df_og['pop_size']==48)&(df_og['true_ratio'].map(Fraction)==Fraction(1/8))].iloc[0]\n",
    "# df1['pca_ratio'] = str(1.0)\n",
    "# df.loc[str(len(df))] = df1\n",
    "df1 = df_og[(df_og['model_kind'] == 'gp')&(df_og['dim_red_kind'] == 'none')&(df_og['pop_size']==64)&(df_og['true_ratio'].map(Fraction)==Fraction(1/8))].iloc[0]\n",
    "\n",
    "df1['pca_ratio'] = str(1.0)\n",
    "df.loc[str(len(df))] = df1\n",
    "ax = bar(df,'pca_ratio', regr=True, baseline_i=8)\n",
    "ax.set_xlabel('pca reduction ratio')\n",
    "ax.set_title('PCA + GP')\n",
    "\n",
    "save_and_show('pca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_og\n",
    "df = df[(df['model_kind'] == 'gp')& (df['dim_red_kind'] == 'none')]  \n",
    "df = default_groupby(df, ['true_evaluations', 'pop_size'])\n",
    "pures2 = pures.set_index(pures['pop_size'].map(lambda n: (n,n)))\n",
    "df = pd.concat([df, pures2])\n",
    "ax = bar(df, print_table=False)\n",
    "\n",
    "save_and_show('pop_evals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_og\n",
    "df = df[(df['model_kind'] == 'gp')]  \n",
    "ax = bar(df, 'dim_red')\n",
    "save_and_show('gp_dim_red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_og\n",
    "ax = bar(df, 'dim_red_kind', 'elapsed_time')\n",
    "ax.set_ylabel('Iteration Time (ms)')\n",
    "save_and_show('elapsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_og\n",
    "df = df[(df['dim_red_kind'] == 'none')&(df['pop_size']==48)&(df['true_ratio'].map(Fraction)==Fraction(1/8))]  \n",
    "ax = bar(df, 'model')\n",
    "two_layer_tics(ax)\n",
    "save_and_show('models')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim_red\n",
    "df=df_og\n",
    "ax = bar(df, 'dim_red_kind')\n",
    "save_and_show('dim_red_kind')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank models without nodimred \n",
    "df=df_og\n",
    "df1 = df[ (df['true_evaluations']==6) & (df['dim_red_kind'] == 'none')]  \n",
    "ax = bar(df, 'model')\n",
    "plt.xticks(rotation=90, size= 'small')\n",
    "save_and_show('models')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#popsize,true_evals           with only gp\n",
    "from fractions import Fraction\n",
    "df=df_og\n",
    "df=df[(df['model_kind'] == 'gp')&(df['dim_red_kind']=='none')]\n",
    "\n",
    "ax = bar(df, 'true_ratio',index_mapper = lambda a: Fraction(a))\n",
    "ax.set_label('dim red, true evals, aux evals')\n",
    "ax.set_xlabel('truly evaluated fraction of population')\n",
    "ax.set_ylabel('rank percentile avg')\n",
    "\n",
    "labels = [item.get_text() for item in ax.get_xticklabels()]\n",
    "labels[1] = '1/12'\n",
    "ax.set_xticklabels(labels)\n",
    "save_and_show('popsize_evals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_og' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#popsize,true_evals           with only gp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mdf_og\u001b[49m\n\u001b[0;32m      3\u001b[0m df\u001b[38;5;241m=\u001b[39mdf[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_kind\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgp\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m&\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdim_red_kind\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m default_groupby(df, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue_evaluations\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpop_size\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_og' is not defined"
     ]
    }
   ],
   "source": [
    "#popsize,true_evals           with only gp\n",
    "df=df_og\n",
    "df=df[(df['model_kind'] == 'gp')&(df['dim_red_kind']=='none')]\n",
    "df = default_groupby(df, ['true_evaluations','pop_size'])\n",
    "ax = bar(df)\n",
    "ax.set_label('dim red, true evals, aux evals')\n",
    "ax.set_xlabel('population: (true evaluated, generated)')\n",
    "ax.set_ylabel('rank percentile avg')\n",
    "# xlabel = ax.get_xlabel()\n",
    "# ax.set_xlabel([1,2,3], rotation='horizontal')\n",
    "# plt.savefig(\"graphs/pop.png\")\n",
    "# plt.pause(0.01)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " c:\\Users\\Admin\\Desktop\\Diplomka\\ranks.py:160: FutureWarning:Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n"
     ]
    }
   ],
   "source": [
    "# df=pca_df[(pca_df['scale_train']==True)&(pca_df['function']==8)&(pca_df['instance']==1)]\n",
    "df = df_og\n",
    "df =df[ \n",
    "    (df['dim']==2)&\n",
    "    (df['function']<=5)\n",
    "       \n",
    "]\n",
    "ranks.plot_ranks(df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_og' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf_og\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnote\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m out_folders \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoco_directory\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_og' is not defined"
     ]
    }
   ],
   "source": [
    "df = df_og.copy()\n",
    "df = df[df['note']=='']\n",
    "out_folders = df['coco_directory'].unique()\n",
    "np.array(out_folders)[True, ]\n",
    "ranks.coco_plot(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
